from django.db import models
from django.utils import timezone
from django.contrib.auth.models import User


class Server(models.Model):
    class Meta:
        verbose_name = "Link Connection"
        verbose_name_plural = "Link Connections"

    name = models.CharField(max_length=100)
    ip_address = models.GenericIPAddressField()
    username = models.CharField(max_length=100)
    port = models.IntegerField(default=22)
    ssh_key_deployed = models.BooleanField(default=False, help_text="Whether SSH key has been deployed")
    ssh_key_deployed_at = models.DateTimeField(null=True, blank=True)
    suppress_alerts = models.BooleanField(default=False, help_text="Whether to suppress email alerts for this server")
    suspend_monitoring = models.BooleanField(default=False, help_text="Whether to suspend monitoring for this server")

    def __str__(self):
        return self.name


class MonitoredLog(models.Model):
    class ParserChoices(models.TextChoices):
        GENERIC_ERROR = "GENERIC_ERROR", "Generic Error Log"
        APACHE_ERROR = "APACHE_ERROR", "Apache Error Log"
        NGINX_ERROR = "NGINX_ERROR", "Nginx Error Log"
        CRON_STATUS = "CRON_STATUS", "Cron Status Log"
        EXIM_ERROR = "EXIM_ERROR", "Exim Error Log"
        POSTFIX_ERROR = "POSTFIX_ERROR", "Postfix Error Log"
        MYSQL_ERROR = "MYSQL_ERROR", "MySQL Error Log"
        MARIADB_ERROR = "MARIADB_ERROR", "MariaDB Error Log"
        CUSTOM_APP = "CUSTOM_APP", "Custom Application"
    
    class ServiceChoices(models.TextChoices):
        APACHE = "apache", "Apache"
        NGINX = "nginx", "Nginx"
        EXIM = "exim", "Exim"
        POSTFIX = "postfix", "Postfix"
        MYSQL = "mysql", "MySQL"
        MARIADB = "mariadb", "MariaDB"
        CUSTOM = "custom", "Custom App"

    server = models.ForeignKey(Server, on_delete=models.CASCADE)
    application_name = models.CharField(max_length=50)
    service_type = models.CharField(
        max_length=20,
        choices=ServiceChoices.choices,
        default=ServiceChoices.CUSTOM,
        help_text="Service type for automatic log path detection"
    )
    log_path = models.CharField(max_length=255)
    last_read_offset = models.BigIntegerField(default=0)
    last_scan_time = models.DateTimeField(null=True, blank=True, help_text="Last time logs were scanned")
    parser_type = models.CharField(
        max_length=20,
        choices=ParserChoices.choices,
        default=ParserChoices.GENERIC_ERROR
    )
    enabled = models.BooleanField(default=True, help_text="Enable/disable log troubleshooting for this log")
    scan_from_days = models.IntegerField(default=1, help_text="Start scanning from this many days ago (default: 1 day)")

    class Meta:
        verbose_name = "Track Activity"
        verbose_name_plural = "Track Activities"
        unique_together = [["server", "log_path"]]

    def __str__(self):
        return f"{self.application_name} on {self.server.name}"

    def get_default_log_path(self):
        """Get default log path based on service type"""
        defaults = {
            'apache': '/var/log/apache2/error.log',
            'nginx': '/var/log/nginx/error.log',
            'exim': '/var/log/exim4/mainlog',
            'postfix': '/var/log/mail.log',
            'mysql': '/var/log/mysql/error.log',
            'mariadb': '/var/log/mysql/error.log',
        }
        return defaults.get(self.service_type, '')


class LogEvent(models.Model):
    monitored_log = models.ForeignKey(MonitoredLog, on_delete=models.CASCADE)
    log_level = models.CharField(max_length=50)
    message = models.TextField()
    ip_address = models.GenericIPAddressField(
        null=True,
        blank=True,
        help_text="The client IP address, if available."
    )
    first_seen = models.DateTimeField(default=timezone.now)
    last_seen = models.DateTimeField(default=timezone.now)
    event_count = models.PositiveIntegerField(default=1)
    is_notified = models.BooleanField(default=False)

    class Meta:
        indexes = [
            models.Index(fields=["monitored_log", "message"]),
        ]

    def __str__(self):
        return f"[{self.log_level}] ({self.event_count}x) on {self.monitored_log.application_name}"


class AnalysisRule(models.Model):
    class ActionType(models.TextChoices):
        INVESTIGATE = "INVESTIGATE", "Investigate"
        BLOCK_IP = "BLOCK_IP", "Block IP Address"
        IGNORE = "IGNORE", "Ignore"
        FYI = "FYI", "For Your Information"

    name = models.CharField(max_length=200)
    pattern_to_match = models.CharField(max_length=255, unique=True)
    explanation = models.TextField()
    recommendation = models.CharField(
        max_length=20,
        choices=ActionType.choices,
        default=ActionType.INVESTIGATE
    )
    llm_generated = models.BooleanField(default=False, help_text="Whether this rule was auto-generated by LLM")
    solution = models.TextField(blank=True, default="", help_text="Step-by-step solution commands generated by LLM")

    def __str__(self):
        return self.name


class SystemMetric(models.Model):
    """Stores collected system metrics"""
    server = models.ForeignKey(Server, on_delete=models.CASCADE, related_name="metrics")
    timestamp = models.DateTimeField(default=timezone.now, db_index=True)
    
    # CPU metrics
    cpu_percent = models.FloatField()
    cpu_count = models.IntegerField(null=True, blank=True, help_text="Logical CPU count")
    physical_cpu_count = models.IntegerField(null=True, blank=True, help_text="Physical CPU cores")
    cpu_load_avg_1m = models.FloatField(null=True, blank=True)
    cpu_load_avg_5m = models.FloatField(null=True, blank=True)
    cpu_load_avg_15m = models.FloatField(null=True, blank=True)
    
    # Memory metrics
    memory_total = models.BigIntegerField()  # bytes
    memory_available = models.BigIntegerField()  # bytes
    memory_percent = models.FloatField()
    memory_used = models.BigIntegerField()  # bytes
    memory_buffers = models.BigIntegerField(null=True, blank=True)  # bytes
    memory_cached = models.BigIntegerField(null=True, blank=True)  # bytes
    memory_shared = models.BigIntegerField(null=True, blank=True)  # bytes
    swap_total = models.BigIntegerField(null=True, blank=True)
    swap_used = models.BigIntegerField(null=True, blank=True)
    swap_percent = models.FloatField(null=True, blank=True)
    
    # Disk metrics (JSON field for multiple disks)
    # Enhanced structure: {"/": {"total": ..., "used": ..., "percent": ..., "disk_type": "SSD", "raid": "none", "physical_disk": "sda"}}
    disk_usage = models.JSONField(default=dict)
    
    # Network metrics (JSON field for multiple interfaces)
    network_io = models.JSONField(default=dict)
    network_connections = models.IntegerField(null=True, blank=True)

    # I/O rate metrics (bytes per second)
    disk_io_read = models.BigIntegerField(null=True, blank=True, help_text="Disk read rate (bytes/second)")
    disk_io_write = models.BigIntegerField(null=True, blank=True, help_text="Disk write rate (bytes/second)")
    net_io_sent = models.BigIntegerField(null=True, blank=True, help_text="Network sent rate (bytes/second)")
    net_io_recv = models.BigIntegerField(null=True, blank=True, help_text="Network received rate (bytes/second)")
    
    # Network utilization metrics (percentage of NIC max speed)
    net_utilization_sent = models.FloatField(null=True, blank=True, help_text="Network send utilization % (based on NIC max speed)")
    net_utilization_recv = models.FloatField(null=True, blank=True, help_text="Network receive utilization % (based on NIC max speed)")
    nic_max_speed_bits = models.BigIntegerField(null=True, blank=True, help_text="Total NIC max speed in bits/second (all interfaces)")
    
    # Raw I/O counter values for rate calculation (cumulative totals across all disks)
    disk_read_bytes_total = models.BigIntegerField(null=True, blank=True, help_text="Cumulative disk read bytes (all disks)")
    disk_write_bytes_total = models.BigIntegerField(null=True, blank=True, help_text="Cumulative disk write bytes (all disks)")
    
    # System uptime
    system_uptime_seconds = models.BigIntegerField(null=True, blank=True, help_text="System uptime in seconds (time since last boot)")
    
    # Process context (collected during normal metric collection)
    top_processes = models.JSONField(
        null=True, 
        blank=True,
        help_text="Top processes by CPU/Memory at collection time. Format: {'cpu': [...], 'memory': [...]}"
    )
    
    class Meta:
        ordering = ["-timestamp"]
        indexes = [
            models.Index(fields=["server", "-timestamp"]),
        ]

    def __str__(self):
        return f"{self.server.name} - {self.timestamp}"


class Anomaly(models.Model):
    """Detected anomalies in system metrics"""
    class Severity(models.TextChoices):
        LOW = "LOW", "Low"
        MEDIUM = "MEDIUM", "Medium"
        HIGH = "HIGH", "High"
        CRITICAL = "CRITICAL", "Critical"
    
    server = models.ForeignKey(Server, on_delete=models.CASCADE, related_name="anomalies")
    metric = models.ForeignKey(SystemMetric, on_delete=models.CASCADE, related_name="anomalies")
    timestamp = models.DateTimeField(default=timezone.now, db_index=True)
    
    metric_type = models.CharField(max_length=50)  # "cpu", "memory", "disk", "network"
    metric_name = models.CharField(max_length=100)  # e.g., "cpu_percent", "memory_percent"
    metric_value = models.FloatField()
    anomaly_score = models.FloatField()  # IsolationForest score or ADTK score
    severity = models.CharField(max_length=20, choices=Severity.choices, default=Severity.MEDIUM)
    
    # LLM-generated explanation (optional)
    explanation = models.TextField(blank=True)
    llm_generated = models.BooleanField(default=False)
    
    # Status
    acknowledged = models.BooleanField(default=False)
    resolved = models.BooleanField(default=False)
    resolved_at = models.DateTimeField(null=True, blank=True)
    
    class Meta:
        ordering = ["-timestamp"]
        indexes = [
            models.Index(fields=["server", "-timestamp"]),
            models.Index(fields=["severity", "-timestamp"]),
        ]

    def __str__(self):
        return f"{self.server.name} - {self.metric_type} anomaly at {self.timestamp}"


class Service(models.Model):
    """Detected services on servers"""
    server = models.ForeignKey(Server, on_delete=models.CASCADE, related_name="services")
    name = models.CharField(max_length=100)
    status = models.CharField(max_length=50, default="unknown")  # running, stopped, failed
    service_type = models.CharField(max_length=50, default="systemd")  # systemd, process, port
    port = models.IntegerField(null=True, blank=True)
    process_id = models.CharField(max_length=50, null=True, blank=True)
    last_checked = models.DateTimeField(default=timezone.now)
    monitoring_enabled = models.BooleanField(default=False, help_text="Whether monitoring is enabled for this service")
    
    class Meta:
        unique_together = [["server", "name"]]
        indexes = [
            models.Index(fields=["server", "status"]),
            models.Index(fields=["last_checked"]),
        ]
    
    def __str__(self):
        return f"{self.name} on {self.server.name} ({self.status})"


class MonitoringConfig(models.Model):
    """Configuration for monitoring each server"""
    server = models.OneToOneField(Server, on_delete=models.CASCADE, related_name="monitoring_config")
    
    # Collection settings
    collection_interval_seconds = models.IntegerField(default=60, help_text="Seconds between metric collections")
    adaptive_collection_enabled = models.BooleanField(default=False, help_text="Enable adaptive collection frequency")
    anomaly_detection_interval = models.IntegerField(default=15, help_text="Collection interval when anomaly detected (seconds)")
    enabled = models.BooleanField(default=True)
    
    # Anomaly detection settings
    use_adtk = models.BooleanField(default=True, help_text="Use ADTK (primary) vs IsolationForest (fallback)")
    use_isolation_forest = models.BooleanField(default=False, help_text="Use IsolationForest (fallback)")
    contamination = models.FloatField(default=0.1, help_text="Expected proportion of anomalies (0.0-0.5)")
    window_size = models.IntegerField(default=100, help_text="Number of recent metrics for training")
    
    # ADTK-specific settings
    adtk_threshold_factor = models.FloatField(default=2.0, help_text="Threshold factor for ADTK detectors")
    adtk_window_size = models.IntegerField(default=30, help_text="Window size for ADTK time-series analysis")
    
    # Thresholds (fallback if ML fails)
    cpu_threshold = models.FloatField(default=80.0, help_text="CPU usage threshold (%)")
    memory_threshold = models.FloatField(default=90.0, help_text="Memory usage threshold (%)")
    disk_threshold = models.FloatField(default=90.0, help_text="Disk usage threshold (%)")
    disk_io_threshold = models.FloatField(default=1000.0, help_text="Disk I/O threshold (MB/s)")
    network_io_threshold = models.FloatField(default=1000.0, help_text="Network I/O threshold (MB/s)")
    
    # Selected disk partitions to monitor (JSON array of mount points)
    monitored_disks = models.JSONField(default=list, help_text="List of disk mount points to monitor (e.g., ['/', '/home'])")
    
    # LLM settings
    use_llm_explanation = models.BooleanField(default=True, help_text="Always generate LLM explanations for anomalies")
    
    # Data retention settings
    retention_period_days = models.IntegerField(default=30, help_text="Days to keep raw metrics before deletion")
    aggregation_enabled = models.BooleanField(default=True, help_text="Enable metric aggregation")
    
    # Alert and monitoring control
    alert_suppressed = models.BooleanField(default=False, help_text="Suppress alerts for this server")
    monitoring_suspended = models.BooleanField(default=False, help_text="Suspend monitoring for this server")

    # Service monitoring settings
    monitored_services = models.JSONField(default=list, help_text="List of systemd services to monitor")
    service_failure_alert = models.BooleanField(default=True, help_text="Enable alerts for service failures")
    service_restart_threshold = models.IntegerField(default=2, help_text="Number of restarts allowed in 10 minutes")
    service_down_duration_threshold = models.IntegerField(default=30, help_text="Seconds before down service triggers alert")
    
    class Meta:
        verbose_name = "Monitoring Configuration"
        verbose_name_plural = "Monitoring Configurations"

    def __str__(self):
        return f"Monitoring config for {self.server.name}"


class AggregatedMetric(models.Model):
    """Aggregated metrics for long-term storage"""
    server = models.ForeignKey(Server, on_delete=models.CASCADE, related_name="aggregated_metrics")
    aggregation_type = models.CharField(max_length=20)  # "hourly", "daily"
    timestamp = models.DateTimeField(db_index=True)
    
    # Aggregated values
    cpu_avg = models.FloatField(null=True, blank=True)
    cpu_min = models.FloatField(null=True, blank=True)
    cpu_max = models.FloatField(null=True, blank=True)
    
    memory_avg = models.FloatField(null=True, blank=True)
    memory_min = models.FloatField(null=True, blank=True)
    memory_max = models.FloatField(null=True, blank=True)
    
    disk_avg = models.FloatField(null=True, blank=True)
    disk_min = models.FloatField(null=True, blank=True)
    disk_max = models.FloatField(null=True, blank=True)
    
    metric_count = models.IntegerField(default=0, help_text="Number of raw metrics aggregated")
    
    class Meta:
        unique_together = [["server", "aggregation_type", "timestamp"]]
        indexes = [
            models.Index(fields=["server", "aggregation_type", "-timestamp"]),
        ]
    
    def __str__(self):
        return f"{self.server.name} - {self.aggregation_type} - {self.timestamp}"

class EmailAlertConfig(models.Model):
    """Email configuration for sending alerts"""
    class ProviderChoices(models.TextChoices):
        GMAIL = "gmail", "Gmail"
        OUTLOOK = "outlook", "Outlook / Office365"
        YAHOO = "yahoo", "Yahoo"
        CUSTOM = "custom", "Custom SMTP"

    provider = models.CharField(
        max_length=20,
        choices=ProviderChoices.choices,
        default=ProviderChoices.CUSTOM
    )
    smtp_host = models.CharField(max_length=255, blank=True)
    smtp_port = models.IntegerField(default=587)
    use_tls = models.BooleanField(default=True)
    use_ssl = models.BooleanField(default=False)
    username = models.EmailField(blank=True)
    password = models.CharField(max_length=255, blank=True)  # Will be encrypted
    from_email = models.EmailField(blank=True)
    to_email = models.EmailField(blank=True, help_text="Recipient email address for alerts (comma-separated for multiple)")
    enabled = models.BooleanField(default=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    def get_smtp_config(self):
        """Get SMTP configuration with provider defaults"""
        configs = {
            self.ProviderChoices.GMAIL: {
                'smtp_host': 'smtp.gmail.com',
                'smtp_port': 587,
                'use_tls': True,
                'use_ssl': False,
            },
            self.ProviderChoices.OUTLOOK: {
                'smtp_host': 'smtp.office365.com',
                'smtp_port': 587,
                'use_tls': True,
                'use_ssl': False,
            },
            self.ProviderChoices.YAHOO: {
                'smtp_host': 'smtp.mail.yahoo.com',
                'smtp_port': 465,
                'use_tls': False,
                'use_ssl': True,
            },
            self.ProviderChoices.CUSTOM: {
                'smtp_host': self.smtp_host,
                'smtp_port': self.smtp_port,
                'use_tls': self.use_tls,
                'use_ssl': self.use_ssl,
            }
        }
        return configs[self.provider]
    
    def __str__(self):
        return f"Email Alert Config ({self.provider})"


class AlertHistory(models.Model):
    """History of alerts sent and resolved"""
    class AlertType(models.TextChoices):
        CPU = "CPU", "CPU"
        MEMORY = "Memory", "Memory"
        DISK = "Disk", "Disk"
        CONNECTION = "CONNECTION", "Connection"
        SERVICE = "SERVICE", "Service"
    
    class AlertStatus(models.TextChoices):
        TRIGGERED = "triggered", "Triggered"
        RESOLVED = "resolved", "Resolved"
    
    server = models.ForeignKey(Server, on_delete=models.CASCADE, related_name="alert_history")
    alert_type = models.CharField(max_length=20, choices=AlertType.choices)
    status = models.CharField(max_length=20, choices=AlertStatus.choices, default=AlertStatus.TRIGGERED)
    value = models.FloatField(help_text="Current metric value")
    threshold = models.FloatField(help_text="Threshold value")
    message = models.TextField()
    recipients = models.TextField(help_text="Comma-separated list of email recipients")
    sent_at = models.DateTimeField(default=timezone.now, db_index=True)
    resolved_at = models.DateTimeField(null=True, blank=True)
    
    class Meta:
        ordering = ["-sent_at"]
        indexes = [
            models.Index(fields=["server", "-sent_at"]),
            models.Index(fields=["status", "-sent_at"]),
        ]
        verbose_name = "Alert History"
        verbose_name_plural = "Alert History"
    
    def __str__(self):
        return f"{self.server.name} - {self.alert_type} {self.status} at {self.sent_at}"


class Role(models.Model):
    """RBAC Role - defines a set of permissions that can be assigned to users"""
    name = models.CharField(max_length=100, unique=True)
    description = models.TextField(blank=True, help_text="Description of this role's responsibilities")
    is_protected = models.BooleanField(default=False, help_text="Protected roles cannot be renamed or deleted")

    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        verbose_name = "Role"
        verbose_name_plural = "Roles"
        ordering = ['name']

    def __str__(self):
        return self.name

    def get_privileges(self):
        """Get all privileges for this role"""
        return self.role_privileges.select_related('privilege')


class Privilege(models.Model):
    """Individual permission that can be assigned to roles"""
    key = models.CharField(max_length=100, unique=True, help_text="Machine-readable key (e.g., 'view_dashboard')")
    label = models.CharField(max_length=200, help_text="Human-readable label (e.g., 'View Dashboard')")

    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        verbose_name = "Privilege"
        verbose_name_plural = "Privileges"
        ordering = ['key']

    def __str__(self):
        return self.label


class RolePrivilege(models.Model):
    """Many-to-many mapping between roles and privileges"""
    role = models.ForeignKey(Role, on_delete=models.CASCADE, related_name='role_privileges')
    privilege = models.ForeignKey(Privilege, on_delete=models.CASCADE, related_name='role_privileges')

    class Meta:
        unique_together = [['role', 'privilege']]
        verbose_name = "Role Privilege"
        verbose_name_plural = "Role Privileges"

    def __str__(self):
        return f"{self.role.name} - {self.privilege.label}"


class UserACL(models.Model):
    """Access Control List for Staff Users - now uses role-based permissions"""
    user = models.OneToOneField(User, on_delete=models.CASCADE, related_name='acl')
    role = models.ForeignKey(Role, on_delete=models.SET_NULL, null=True, blank=True,
                           help_text="Role that defines this user's permissions")

    # DEPRECATED: These boolean flags are kept for backward compatibility
    # but should be removed after migration to role-based system
    can_view_dashboard = models.BooleanField(default=True, help_text="[DEPRECATED] Use role privileges")
    can_edit_thresholds = models.BooleanField(default=False, help_text="[DEPRECATED] Use role privileges")
    can_halt_monitoring = models.BooleanField(default=False, help_text="[DEPRECATED] Use role privileges")
    can_mute_notifications = models.BooleanField(default=False, help_text="[DEPRECATED] Use role privileges")
    can_add_server = models.BooleanField(default=False, help_text="[DEPRECATED] Use role privileges")
    can_edit_server = models.BooleanField(default=False, help_text="[DEPRECATED] Use role privileges")
    can_delete_server = models.BooleanField(default=False, help_text="[DEPRECATED] Use role privileges")

    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        verbose_name = "User ACL"
        verbose_name_plural = "User ACLs"
        ordering = ['user__username']

    def __str__(self):
        role_name = self.role.name if self.role else "No Role"
        return f"ACL for {self.user.username} ({role_name})"

    def has_privilege(self, privilege_key):
        """Check if user has a specific privilege"""
        # Root Admin (superuser) has all privileges
        if self.user.is_superuser:
            return True

        # Check role-based privileges
        if self.role and self.role.role_privileges.filter(privilege__key=privilege_key).exists():
            return True

        return False

    def get_all_privileges(self):
        """Get all privilege keys for this user"""
        if self.user.is_superuser:
            # Root Admin has all privileges
            return Privilege.objects.values_list('key', flat=True)

        if self.role:
            return self.role.role_privileges.values_list('privilege__key', flat=True)

        return []

    @classmethod
    def get_or_create_for_user(cls, user):
        """Get or create ACL for a user"""
        acl, created = cls.objects.get_or_create(user=user)
        if created:
            if user.is_superuser:
                # For superusers, assign Root Admin role if it exists
                try:
                    root_admin_role = Role.objects.get(name="Root Admin")
                    acl.role = root_admin_role
                    acl.save()
                except Role.DoesNotExist:
                    # If Root Admin role doesn't exist, superuser still gets all privileges via has_privilege checks
                    pass
            else:
                # For regular staff users, assign default Viewer role if it exists
                try:
                    viewer_role = Role.objects.get(name="Viewer")
                    acl.role = viewer_role
                    acl.save()
                except Role.DoesNotExist:
                    # Fallback to old boolean system if roles not yet set up
                    acl.can_view_dashboard = True
                    acl.save()
        return acl


class ServerHeartbeat(models.Model):
    """Tracks heartbeat signals from agent scripts on monitored servers"""
    server = models.ForeignKey(Server, on_delete=models.CASCADE, related_name="heartbeats")
    last_heartbeat = models.DateTimeField(default=timezone.now, db_index=True, help_text="Last heartbeat timestamp from agent")
    agent_version = models.CharField(max_length=50, blank=True, null=True, help_text="Optional agent version string")
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        verbose_name = "Server Heartbeat"
        verbose_name_plural = "Server Heartbeats"
        indexes = [
            models.Index(fields=["server", "-last_heartbeat"]),
            models.Index(fields=["-last_heartbeat"]),
        ]
        unique_together = [["server"]]
    
    def __str__(self):
        return f"Heartbeat for {self.server.name} - {self.last_heartbeat}"
